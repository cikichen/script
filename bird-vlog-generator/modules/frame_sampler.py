"""å…³é”®å¸§æå–æ¨¡å— - å¸¦ YOLO é¸Ÿç±»æ£€æµ‹"""

import cv2
import os
import sys
import numpy as np
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import FRAME_SAMPLE_INTERVAL, MAX_FRAMES_PER_VIDEO


def extract_keyframes(
    video_path: str,
    output_dir: str,
    method: str = "bird_detect",
    max_frames: int = 3  # æ¯ä¸ªè§†é¢‘æœ€å¤š 3 å¸§ï¼ˆå‚è€ƒ Reli æ–¹æ¡ˆï¼‰
) -> list[dict]:
    """ä»è§†é¢‘ä¸­æå–å…³é”®å¸§
    
    Args:
        video_path: è¾“å…¥è§†é¢‘è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        method: æå–æ–¹æ³• 
            - "simple": ç­‰é—´éš”æŠ½å¸§
            - "smart": åœºæ™¯å˜åŒ–+è¿åŠ¨æ£€æµ‹
            - "bird_detect": YOLO é¸Ÿç±»æ£€æµ‹ï¼ˆæ¨èï¼‰
        max_frames: æœ€å¤§å¸§æ•°
        
    Returns:
        å…³é”®å¸§ä¿¡æ¯åˆ—è¡¨ [{"path": str, "timestamp": float, "video_path": str, ...}, ...]
    """
    if max_frames is None:
        max_frames = MAX_FRAMES_PER_VIDEO
    
    if method == "simple":
        return extract_keyframes_simple(video_path, output_dir, max_frames)
    elif method == "smart":
        return extract_keyframes_smart(video_path, output_dir, max_frames)
    else:
        return extract_keyframes_with_bird_detection(video_path, output_dir, max_frames)


def extract_keyframes_simple(video_path: str, output_dir: str, max_frames: int = 20) -> list[dict]:
    """ç®€å•ç­‰é—´éš”æŠ½å¸§"""
    os.makedirs(output_dir, exist_ok=True)
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
    
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps if fps > 0 else 0
    
    print(f"  è§†é¢‘ä¿¡æ¯: {duration:.1f}ç§’, {fps:.1f}fps, {total_frames}å¸§")
    
    frame_interval = int(fps * FRAME_SAMPLE_INTERVAL)
    if frame_interval <= 0:
        frame_interval = 30
    
    frame_infos = []
    frame_count = 0
    saved_count = 0
    
    while cap.isOpened() and saved_count < max_frames:
        ret, frame = cap.read()
        if not ret:
            break
        
        if frame_count % frame_interval == 0:
            timestamp = frame_count / fps
            path = os.path.join(output_dir, f"frame_{saved_count:04d}_t{int(timestamp)}.jpg")
            cv2.imwrite(path, frame)
            frame_infos.append({
                "path": path,
                "timestamp": timestamp,
                "video_path": video_path,
                "frame_index": saved_count
            })
            saved_count += 1
        
        frame_count += 1
    
    cap.release()
    return frame_infos


def extract_keyframes_with_bird_detection(
    video_path: str,
    output_dir: str,
    max_frames: int = 20,
    sample_interval: float = 5.0,  # æ¯ 5 ç§’æ£€æµ‹ä¸€æ¬¡
    confidence: float = 0.25
) -> list[dict]:
    """ä½¿ç”¨ YOLO æ£€æµ‹é¸Ÿç±»ï¼Œåªä¿ç•™æœ‰é¸Ÿçš„å¸§
    
    æµç¨‹ï¼š
    1. æ¯ sample_interval ç§’å–ä¸€å¸§
    2. ç”¨ YOLO æ£€æµ‹æ˜¯å¦æœ‰é¸Ÿ
    3. åªä¿ç•™æœ‰é¸Ÿçš„å¸§
    4. å¦‚æœæœ‰é¸Ÿçš„å¸§è¶…è¿‡ max_framesï¼ŒæŒ‰ç½®ä¿¡åº¦æ’åºå– top
    """
    from modules.bird_detector import detect_bird_in_frame
    
    os.makedirs(output_dir, exist_ok=True)
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
    
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps if fps > 0 else 0
    
    print(f"  è§†é¢‘ä¿¡æ¯: {duration:.1f}ç§’, {fps:.1f}fps, {total_frames}å¸§")
    
    frame_interval = int(fps * sample_interval)
    if frame_interval <= 0:
        frame_interval = int(fps * 5)
    
    # æ”¶é›†æ‰€æœ‰å€™é€‰å¸§
    candidates = []  # [(frame_idx, timestamp, frame, confidence, bird_count)]
    frame_count = 0
    checked_count = 0
    
    print(f"  ğŸ” YOLO é¸Ÿç±»æ£€æµ‹ä¸­...")
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        if frame_count % frame_interval == 0:
            checked_count += 1
            timestamp = frame_count / fps
            
            # YOLO æ£€æµ‹
            result = detect_bird_in_frame(frame, confidence=confidence)
            
            if result["has_bird"]:
                candidates.append({
                    "frame_idx": frame_count,
                    "timestamp": timestamp,
                    "frame": frame.copy(),
                    "confidence": result["confidence"],
                    "bird_count": result["bird_count"]
                })
                print(f"    âœ“ å‘ç°é¸Ÿç±» @ {timestamp:.1f}s (ç½®ä¿¡åº¦: {result['confidence']:.2f})", end="\r")
        
        frame_count += 1
    
    cap.release()
    print()
    
    print(f"  æ£€æŸ¥äº† {checked_count} å¸§ï¼Œå‘ç° {len(candidates)} å¸§æœ‰é¸Ÿ")
    
    # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°é¸Ÿï¼Œå›é€€åˆ°ç­‰é—´éš”æŠ½å¸§
    if not candidates:
        print(f"  æœªæ£€æµ‹åˆ°é¸Ÿç±»ï¼Œä½¿ç”¨ç­‰é—´éš”æŠ½å¸§...")
        return extract_keyframes_simple(video_path, output_dir, max_frames)
    
    # æŒ‰ç½®ä¿¡åº¦æ’åºï¼Œå– top max_frames
    candidates.sort(key=lambda x: x["confidence"], reverse=True)
    selected = candidates[:max_frames]
    
    # æŒ‰æ—¶é—´é¡ºåºæ’åº
    selected.sort(key=lambda x: x["timestamp"])
    
    # ä¿å­˜å¸§
    frame_infos = []
    for i, cand in enumerate(selected):
        path = os.path.join(output_dir, f"frame_{i:04d}_t{int(cand['timestamp'])}.jpg")
        cv2.imwrite(path, cand["frame"])
        frame_infos.append({
            "path": path,
            "timestamp": cand["timestamp"],
            "video_path": video_path,
            "frame_index": i,
            "bird_confidence": cand["confidence"],
            "bird_count": cand["bird_count"]
        })
    
    print(f"  âœ“ æœ€ç»ˆé€‰æ‹© {len(frame_infos)} å¸§ï¼ˆæœ‰é¸Ÿï¼‰")
    
    return frame_infos


def extract_keyframes_smart(video_path: str, output_dir: str, max_frames: int = 20) -> list[dict]:
    """æ™ºèƒ½å…³é”®å¸§æå–ï¼šåœºæ™¯å˜åŒ–+è¿åŠ¨æ£€æµ‹"""
    os.makedirs(output_dir, exist_ok=True)
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
    
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps if fps > 0 else 0
    
    print(f"  è§†é¢‘ä¿¡æ¯: {duration:.1f}ç§’, {fps:.1f}fps, {total_frames}å¸§")
    
    min_frame_gap = int(fps * 3)
    scene_threshold = 0.15
    motion_threshold = 5
    blur_threshold = 50
    
    candidates = []
    prev_frame = None
    prev_hist = None
    frame_count = 0
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
        hist = cv2.normalize(hist, hist).flatten()
        
        scene_score = 0
        if prev_hist is not None:
            scene_score = 1 - cv2.compareHist(prev_hist, hist, cv2.HISTCMP_CORREL)
        
        motion_score = 0
        if prev_frame is not None:
            diff = cv2.absdiff(gray, prev_frame)
            motion_score = np.mean(diff)
        
        blur_score = cv2.Laplacian(gray, cv2.CV_64F).var()
        timestamp = frame_count / fps
        
        if blur_score > blur_threshold:
            total_score = scene_score * 0.4 + (motion_score / 100) * 0.4 + (blur_score / 1000) * 0.2
            
            if scene_score > scene_threshold or motion_score > motion_threshold:
                candidates.append((frame_count, total_score, frame.copy(), timestamp))
        
        prev_frame = gray.copy()
        prev_hist = hist
        frame_count += 1
    
    cap.release()
    
    print(f"  æ£€æµ‹åˆ° {len(candidates)} ä¸ªå€™é€‰å…³é”®å¸§")
    
    selected_frames = select_distributed_frames(candidates, total_frames, min_frame_gap, max_frames)
    
    frame_infos = []
    for i, (frame_idx, score, frame, timestamp) in enumerate(selected_frames):
        path = os.path.join(output_dir, f"frame_{i:04d}_t{int(timestamp)}.jpg")
        cv2.imwrite(path, frame)
        frame_infos.append({
            "path": path,
            "timestamp": timestamp,
            "video_path": video_path,
            "frame_index": i,
            "score": score
        })
    
    print(f"  âœ“ æœ€ç»ˆé€‰æ‹© {len(frame_infos)} å¸§")
    
    if len(frame_infos) < 3:
        print(f"  æ™ºèƒ½æ£€æµ‹å¸§æ•°ä¸è¶³ï¼Œè¡¥å……ç­‰é—´éš”å¸§...")
        return extract_keyframes_simple(video_path, output_dir, max_frames)
    
    return frame_infos


def select_distributed_frames(candidates, total_frames, min_gap, max_count):
    """ä»å€™é€‰å¸§ä¸­é€‰æ‹©åˆ†å¸ƒå‡åŒ€çš„å…³é”®å¸§"""
    if not candidates:
        return []
    
    sorted_candidates = sorted(candidates, key=lambda x: x[1], reverse=True)
    
    selected = []
    used_ranges = []
    
    for frame_idx, score, frame, timestamp in sorted_candidates:
        if len(selected) >= max_count:
            break
        
        too_close = False
        for used_idx in used_ranges:
            if abs(frame_idx - used_idx) < min_gap:
                too_close = True
                break
        
        if not too_close:
            selected.append((frame_idx, score, frame, timestamp))
            used_ranges.append(frame_idx)
    
    selected.sort(key=lambda x: x[0])
    return selected


def get_video_duration(video_path: str) -> float:
    """è·å–è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰"""
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    cap.release()
    return total_frames / fps if fps > 0 else 0


def extract_clip(video_path: str, start_sec: float, end_sec: float, output_path: str) -> str:
    """æå–è§†é¢‘ç‰‡æ®µ"""
    import subprocess
    
    cmd = [
        'ffmpeg', '-y',
        '-ss', str(start_sec),
        '-i', video_path,
        '-t', str(end_sec - start_sec),
        '-c:v', 'libx264',
        '-c:a', 'aac',
        '-preset', 'fast',
        output_path
    ]
    subprocess.run(cmd, capture_output=True, check=True)
    
    return output_path
