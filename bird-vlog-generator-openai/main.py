#!/usr/bin/env python3
"""è§‚é¸Ÿ Vlog ä¸€é”®ç”Ÿæˆå™¨ - ä¸»ç¨‹åºï¼ˆæ”¯æŒå¤šè§†é¢‘ + åŠ¨æ€ç‰‡æ®µï¼‰"""

import os
import sys
import json
import argparse
import glob
from datetime import datetime

from tqdm import tqdm
from config import OUTPUT_DIR, HIGHLIGHT_MIN_SCORE
from modules.frame_sampler import extract_keyframes, get_video_duration
from modules.bedrock_analyzer import batch_analyze, filter_highlights
from modules.script_generator import generate_script, generate_script_with_segments, generate_subtitles, generate_subtitles_for_segments, save_srt
from modules.polly_tts import text_to_speech
from modules.video_composer import compose_video, create_slideshow, compose_from_highlights


def get_video_files(input_path: str) -> list[str]:
    """è·å–è¾“å…¥è·¯å¾„ä¸­çš„æ‰€æœ‰è§†é¢‘æ–‡ä»¶"""
    video_extensions = ('.mp4', '.avi', '.mov', '.mkv', '.webm', '.flv')
    
    if os.path.isfile(input_path):
        return [input_path]
    elif os.path.isdir(input_path):
        videos = []
        for ext in video_extensions:
            videos.extend(glob.glob(os.path.join(input_path, f'*{ext}')))
            videos.extend(glob.glob(os.path.join(input_path, f'*{ext.upper()}')))
        return sorted(videos)
    else:
        raise ValueError(f"è·¯å¾„ä¸å­˜åœ¨: {input_path}")




def generate_vlog(
    input_path: str,
    output_dir: str = None,
    style: str = "æ¸©é¦¨",
    mode: str = "video",
    merge: bool = False,
    birds: str = None,
    duration: float = None,
    workers: int = 5
) -> str:
    """ä¸€é”®ç”Ÿæˆè§‚é¸Ÿ Vlog"""
    if output_dir is None:
        output_dir = OUTPUT_DIR
    
    video_files = get_video_files(input_path)
    if not video_files:
        raise ValueError(f"æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {input_path}")
    
    print("=" * 50)
    print("ğŸ¦ è§‚é¸Ÿ Vlog ä¸€é”®ç”Ÿæˆå™¨")
    print("=" * 50)
    print(f"è¾“å…¥: {input_path}")
    print(f"å‘ç° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
    if birds:
        print(f"ä¸»è§’: {birds}")
    if duration:
        print(f"ç›®æ ‡æ—¶é•¿: {duration}ç§’")
    print()
    
    if merge and len(video_files) > 1:
        return generate_merged_vlog(video_files, output_dir, style, mode, birds, duration, workers)
    else:
        results = []
        for i, video in enumerate(video_files):
            print(f"\n{'='*50}")
            print(f"å¤„ç†è§†é¢‘ [{i+1}/{len(video_files)}]: {os.path.basename(video)}")
            print(f"{'='*50}\n")
            result = process_single_video(video, output_dir, style, mode, birds, duration, workers)
            results.append(result)
        
        if len(results) == 1:
            return results[0]
        else:
            print(f"\nâœ… å…¨éƒ¨å®Œæˆï¼å…±ç”Ÿæˆ {len(results)} ä¸ª Vlog")
            return output_dir


def process_single_video(
    input_video: str,
    output_dir: str,
    style: str,
    mode: str,
    birds: str = None,
    duration: float = None,
    workers: int = 5
) -> str:
    """å¤„ç†å•ä¸ªè§†é¢‘"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    video_name = os.path.splitext(os.path.basename(input_video))[0]
    work_dir = os.path.join(output_dir, f"vlog_{video_name}_{timestamp}")
    os.makedirs(work_dir, exist_ok=True)
    
    print(f"è¾“å‡ºç›®å½•: {work_dir}")
    print()
    
    # 1. æå–å…³é”®å¸§
    print("ğŸ“· æ­¥éª¤ 1/5: æå–å…³é”®å¸§...")
    frames_dir = os.path.join(work_dir, "frames")
    frame_infos = extract_keyframes(input_video, frames_dir)
    print(f"  âœ“ æå–äº† {len(frame_infos)} å¸§")
    print()
    
    pbar = tqdm(total=len(frame_infos), desc="ğŸ¤– AI è§†è§‰åˆ†æ", unit="frame")
    def progress(current, total):
        pbar.update(1)
    
    analysis_results = batch_analyze(frame_infos, max_workers=workers, progress_callback=progress)
    pbar.close()
    print()
    
    # ä¿å­˜åˆ†æç»“æœ
    analysis_file = os.path.join(work_dir, "analysis.json")
    with open(analysis_file, "w", encoding="utf-8") as f:
        json.dump(analysis_results, f, ensure_ascii=False, indent=2)
    
    highlights = filter_highlights(analysis_results, min_score=HIGHLIGHT_MIN_SCORE)
    print(f"  âœ“ åˆ†æå®Œæˆï¼Œå‘ç° {len(highlights)} ä¸ªç²¾å½©ç‰‡æ®µ")
    print()
    
    # 3. ç”Ÿæˆè„šæœ¬
    print("ğŸ“ æ­¥éª¤ 3/5: ç”Ÿæˆæ•…äº‹è„šæœ¬...")
    script, segment_subtitles = generate_script_with_segments(
        analysis_results, style=style, expected_bird=birds, target_duration=duration
    )
    
    script_file = os.path.join(work_dir, "script.txt")
    with open(script_file, "w", encoding="utf-8") as f:
        f.write(script)
    
    print(f"  âœ“ è„šæœ¬ç”Ÿæˆå®Œæˆ ({len(script)} å­—)")
    print()
    
    # 4. è¯­éŸ³åˆæˆ
    print("ğŸ™ï¸ æ­¥éª¤ 4/5: è¯­éŸ³åˆæˆ...")
    audio_path = os.path.join(work_dir, "narration.mp3")
    text_to_speech(script, audio_path)
    print(f"  âœ“ è¯­éŸ³åˆæˆå®Œæˆ")
    print()
    
    # è·å–éŸ³é¢‘æ—¶é•¿
    import subprocess
    try:
        result = subprocess.run(
            ['ffprobe', '-v', 'error', '-show_entries', 'format=duration',
             '-of', 'default=noprint_wrappers=1:nokey=1', audio_path],
            capture_output=True, text=True
        )
        audio_duration = float(result.stdout.strip())
    except:
        audio_duration = 10.0
    
    # ç”Ÿæˆå­—å¹•
    num_clips = len(analysis_results)
    clip_duration = audio_duration / num_clips if num_clips > 0 else 5.0
    subtitles = generate_subtitles_for_segments(segment_subtitles, [clip_duration] * num_clips)
    srt_path = os.path.join(work_dir, "subtitles.srt")
    save_srt(subtitles, srt_path)
    

    # 5. è§†é¢‘åˆæˆ
    print("ğŸ¬ æ­¥éª¤ 5/5: è§†é¢‘åˆæˆ...")
    output_path = os.path.join(work_dir, "vlog.mp4")
    
    if mode == "slideshow":
        create_slideshow(frame_infos, audio_path, output_path, subtitle_text=script[:100])
    else:
        # ä¿®æ­£å‚æ•°ï¼šå»æ‰ analysis_resultsï¼Œä¿æŒä¸å‡½æ•°å®šä¹‰ä¸€è‡´
        compose_video(input_video, audio_path, output_path, 
                      subtitle_file=srt_path)
    
    print(f"  âœ“ è§†é¢‘åˆæˆå®Œæˆ")
    print()
    
    return output_path


def generate_merged_vlog(
    video_files: list[str],
    output_dir: str,
    style: str,
    mode: str,
    birds: str = None,
    duration: float = None,
    workers: int = 5
) -> str:
    """å°†å¤šä¸ªè§†é¢‘åˆå¹¶ä¸ºä¸€ä¸ªç²¾å½© Vlog"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    work_dir = os.path.join(output_dir, f"vlog_merged_{timestamp}")
    os.makedirs(work_dir, exist_ok=True)
    
    print(f"è¾“å‡ºç›®å½•: {work_dir}")
    print()
    
    all_frame_infos = []
    
    # 1. ä»æ‰€æœ‰è§†é¢‘æå–å…³é”®å¸§
    print("ğŸ“· æ­¥éª¤ 1/5: æå–æ‰€æœ‰è§†é¢‘çš„å…³é”®å¸§...")
    frames_dir = os.path.join(work_dir, "frames")
    os.makedirs(frames_dir, exist_ok=True)
    
    for i, video in enumerate(video_files):
        print(f"  å¤„ç† [{i+1}/{len(video_files)}]: {os.path.basename(video)}")
        video_frames_dir = os.path.join(frames_dir, f"video_{i:03d}")
        frame_infos = extract_keyframes(video, video_frames_dir)
        all_frame_infos.extend(frame_infos)
    
    print(f"  âœ“ å…±æå– {len(all_frame_infos)} å¸§")
    print()
    
    # 2. AI è§†è§‰åˆ†æ
    print("ğŸ¤– æ­¥éª¤ 2/5: AI è§†è§‰åˆ†æ...")
    pbar = tqdm(total=len(all_frame_infos), desc="ğŸ¤– AI è§†è§‰åˆ†æ", unit="frame")
    def progress(current, total):
        pbar.update(1)
    
    all_analysis = batch_analyze(all_frame_infos, max_workers=workers, progress_callback=progress)
    pbar.close()
    print()
    
    # ä¿å­˜åˆ†æç»“æœ
    analysis_file = os.path.join(work_dir, "analysis.json")
    with open(analysis_file, "w", encoding="utf-8") as f:
        json.dump(all_analysis, f, ensure_ascii=False, indent=2)
    
    # ç­›é€‰å¯ç”¨ç‰‡æ®µ (åŠ¨æ€å‡é™çº§ç­›é€‰ç­–ç•¥)
    # 1. ä¼˜å…ˆå°è¯•ä½¿ç”¨é…ç½®çš„é«˜åˆ†é˜ˆå€¼ (é»˜è®¤ 7)
    usable_clips = [r for r in all_analysis if r.get("highlight_score", 0) >= HIGHLIGHT_MIN_SCORE and r.get("video_path")]
    
    # 2. å¦‚æœé«˜åˆ†ç‰‡æ®µå¤ªå°‘ (å°‘äº 3 ä¸ª)ï¼Œå°è¯•é™çº§åˆ° 4 åˆ† (æ™®é€šç´ æ)
    if len(usable_clips) < 3:
        usable_clips = [r for r in all_analysis if r.get("highlight_score", 0) >= 4 and r.get("video_path")]
        
    # 3. å¦‚æœä¾ç„¶æ²¡æœ‰ï¼Œåˆ™ä¿åº•ä½¿ç”¨æ‰€æœ‰æœ‰è§†é¢‘è·¯å¾„çš„ç‰‡æ®µ
    if not usable_clips:
        usable_clips = [r for r in all_analysis if r.get("video_path")]
    
    if not usable_clips:
        usable_clips = all_frame_infos
    
    print(f"  âœ“ åˆ†æå®Œæˆï¼Œå°†ä½¿ç”¨ {len(usable_clips)} ä¸ªç‰‡æ®µ")
    print()
    
    # 3. ç”Ÿæˆè„šæœ¬ï¼ˆå¸¦ç‰‡æ®µå¯¹åº”ï¼‰
    print("ğŸ“ æ­¥éª¤ 3/5: ç”Ÿæˆæ•…äº‹è„šæœ¬...")
    script, segment_subtitles = generate_script_with_segments(
        usable_clips, style=style, expected_bird=birds, target_duration=duration
    )
    
    script_file = os.path.join(work_dir, "script.txt")
    with open(script_file, "w", encoding="utf-8") as f:
        f.write(script)
    
    print(f"  âœ“ è„šæœ¬ç”Ÿæˆå®Œæˆ ({len(script)} å­—)")
    print(f"  âœ“ å·²ä¸º {len(segment_subtitles)} ä¸ªç‰‡æ®µç”Ÿæˆå¯¹åº”å­—å¹•")
    print()
    
    # 4. é€æ®µè¯­éŸ³åˆæˆ (è§£å†³éŸ³ç”»åŒæ­¥çš„å…³é”®)
    print("ğŸ™ï¸ æ­¥éª¤ 4/5: é€æ®µæ—ç™½åˆæˆ (ç¡®ä¿éŸ³ç”»å®Œç¾åŒ¹é…)...")
    temp_audio_dir = os.path.join(work_dir, "temp_audio")
    os.makedirs(temp_audio_dir, exist_ok=True)
    
    audio_segments = []
    clip_durations = []
    
    for i, seg in enumerate(tqdm(segment_subtitles, desc="ğŸ™ï¸ æ—ç™½åˆæˆ", unit="seg")):
        text = seg.get("text", "")
        if not text:
            # å¦‚æœæŸç‰‡æ®µæ²¡æœ‰æ—ç™½ï¼Œç»™ä¸€ä¸ªé»˜è®¤æ—¶é•¿ï¼ˆå¦‚ 3 ç§’ï¼‰
            clip_durations.append(3.0)
            continue
            
        seg_audio_path = os.path.abspath(os.path.join(temp_audio_dir, f"seg_{i:03d}.mp3"))
        text_to_speech(text, seg_audio_path)
        
        # è·å–è¯¥æ®µè¯­éŸ³çš„æ—¶é•¿
        from modules.polly_tts import get_audio_duration
        seg_duration = get_audio_duration(seg_audio_path)
        
        audio_segments.append(seg_audio_path)
        clip_durations.append(seg_duration)
    
    # åˆå¹¶æ‰€æœ‰éŸ³é¢‘
    audio_path = os.path.abspath(os.path.join(work_dir, "narration.mp3"))
    audio_list_file = os.path.abspath(os.path.join(temp_audio_dir, "audio_list.txt"))
    with open(audio_list_file, 'w', encoding='utf-8') as f:
        for seg_audio in audio_segments:
            # ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œå¹¶è½¬ä¹‰å•å¼•å·ä»¥é˜²è·¯å¾„åŒ…å«ç‰¹æ®Šå­—ç¬¦
            safe_path = seg_audio.replace("'", "'\\''")
            f.write(f"file '{safe_path}'\n")
            
    try:
        import subprocess
        subprocess.run([
            'ffmpeg', '-y', '-f', 'concat', '-safe', '0',
            '-i', audio_list_file, '-c', 'copy', audio_path
        ], capture_output=True, check=True)
    except Exception as e:
        print(f"  éŸ³é¢‘åˆå¹¶å¤±è´¥: {e}ï¼Œå›é€€åˆ°æ•´ä½“åˆæˆæ¨¡å¼")
        text_to_speech(script, audio_path)
    
    print(f"  âœ“ è¯­éŸ³åˆæˆå®Œæˆ")
    print()
    
    # ç”Ÿæˆ SRT å­—å¹•æ–‡ä»¶
    subtitles = generate_subtitles_for_segments(segment_subtitles, clip_durations)
    srt_path = os.path.join(work_dir, "subtitles.srt")
    save_srt(subtitles, srt_path)
    print(f"  âœ“ å­—å¹•å®Œæˆï¼Œå·²æ ¹æ®æ—ç™½åŠ¨æ€è°ƒæ•´æ—¶é—´è½´")
    
    # ä¿å­˜è°ƒè¯•ä¿¡æ¯
    debug_file = os.path.join(work_dir, "debug_segments.json")
    with open(debug_file, "w", encoding="utf-8") as f:
        json.dump({
            "usable_clips_count": len(usable_clips),
            "segment_subtitles_count": len(segment_subtitles),
            "subtitles_count": len(subtitles),
            "clip_durations": clip_durations,
            "segment_subtitles": segment_subtitles
        }, f, ensure_ascii=False, indent=2)
    print()

    # 5. è§†é¢‘åˆæˆ
    print("ğŸ¬ æ­¥éª¤ 5/5: è§†é¢‘åˆæˆ (é‡‡ç”¨åŠ¨æ€æ—¶é•¿æ¨¡å¼)...")
    output_path = os.path.join(work_dir, "vlog.mp4")
    
    if mode == "slideshow":
        create_slideshow(all_frame_infos, audio_path, output_path, subtitle_text=script[:100])
    else:
        # è¿™é‡Œä¼ é€’å…·ä½“çš„æ—¶é•¿åˆ—è¡¨ç»™è§†é¢‘åˆæˆæ¨¡å—
        compose_from_highlights(usable_clips, audio_path, output_path, 
                                 clip_duration=clip_durations, subtitle_file=srt_path)
    
    print(f"  âœ“ è§†é¢‘åˆæˆå®Œæˆ")
    print()
    
    print("=" * 50)
    print(f"âœ… åˆå¹¶ç”Ÿæˆå®Œæˆ!")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {work_dir}")
    print(f"ğŸ¥ æˆå“è§†é¢‘: {output_path}")
    print("=" * 50)
    
    return output_path


def main():
    parser = argparse.ArgumentParser(
        description="è§‚é¸Ÿ Vlog ä¸€é”®ç”Ÿæˆå™¨ - ä½¿ç”¨ AI è‡ªåŠ¨åˆ†æå¹¶ç”Ÿæˆè§‚é¸Ÿè§†é¢‘",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python main.py video.mp4                    # å¤„ç†å•ä¸ªè§†é¢‘
  python main.py ./videos/ --merge            # åˆå¹¶ä¸ºåŠ¨æ€ Vlog
  python main.py ./videos/ --merge --birds "ç¿ é¸Ÿ" --duration 60
  python main.py ./videos/ --merge --workers 10  # ä½¿ç”¨ 10 çº¿ç¨‹å¹¶è¡Œåˆ†æ
        """
    )
    
    parser.add_argument("input", help="è¾“å…¥è§†é¢‘è·¯å¾„æˆ–ç›®å½•")
    parser.add_argument("-o", "--output", help="è¾“å‡ºç›®å½•", default=OUTPUT_DIR)
    parser.add_argument("-s", "--style", help="è„šæœ¬é£æ ¼", 
                        choices=["æ¸©é¦¨", "ä¸“ä¸š", "å¹½é»˜"], default="æ¸©é¦¨")
    parser.add_argument("-m", "--mode", help="è¾“å‡ºæ¨¡å¼",
                        choices=["video", "slideshow"], default="video")
    parser.add_argument("--merge", action="store_true",
                        help="å°†å¤šä¸ªè§†é¢‘åˆå¹¶ä¸ºä¸€ä¸ª Vlog")
    parser.add_argument("--birds", "--bird", help="æŒ‡å®šé¢„æœŸè§‚å¯Ÿåˆ°çš„é¸Ÿç±»åç§°")
    parser.add_argument("--duration", type=float, help="è®¾ç½®ç›®æ ‡ Vlog ç†æƒ³æ—¶é•¿ï¼ˆç§’ï¼‰")
    parser.add_argument("--workers", type=int, default=5, help="AI åˆ†æå¹¶è¡Œçº¿ç¨‹æ•° (é»˜è®¤: 5)")
    
    args = parser.parse_args()
    
    if not os.path.exists(args.input):
        print(f"é”™è¯¯: è·¯å¾„ä¸å­˜åœ¨: {args.input}")
        sys.exit(1)
    
    try:
        generate_vlog(
            input_path=args.input,
            output_dir=args.output,
            style=args.style,
            mode=args.mode,
            merge=args.merge,
            birds=args.birds,
            duration=args.duration,
            workers=args.workers
        )
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
